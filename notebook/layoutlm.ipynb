{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pytesseract\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "import torch\n",
    "from datasets import Dataset, Features, Sequence, ClassLabel, Value, Array2D\n",
    "from transformers import LayoutLMTokenizer, LayoutLMForSequenceClassification, AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytesseract.pytesseract.tesseract_cmd = 'C:\\\\Program Files\\\\Tesseract-OCR\\\\tesseract.exe'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'email': 0, 'resume': 1, 'scientific_publication': 2}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_path = \"../small_data\"\n",
    "labels = [label for label in os.listdir(dataset_path)]\n",
    "idx2label = {v: k for v, k in enumerate(labels)}\n",
    "label2idx = {k: v for v, k in enumerate(labels)}\n",
    "label2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150 training examples, 15 validation examples\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../small_data/email/doc_000042.png</td>\n",
       "      <td>email</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../small_data/email/doc_000046.png</td>\n",
       "      <td>email</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../small_data/email/doc_000076.png</td>\n",
       "      <td>email</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../small_data/email/doc_000079.png</td>\n",
       "      <td>email</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../small_data/email/doc_000111.png</td>\n",
       "      <td>email</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           image_path  label\n",
       "0  ../small_data/email/doc_000042.png  email\n",
       "1  ../small_data/email/doc_000046.png  email\n",
       "2  ../small_data/email/doc_000076.png  email\n",
       "3  ../small_data/email/doc_000079.png  email\n",
       "4  ../small_data/email/doc_000111.png  email"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images = []\n",
    "labels = []\n",
    "\n",
    "for label in os.listdir(dataset_path):\n",
    "    images.extend([\n",
    "        f\"{dataset_path}/{label}/{img_name}\" for img_name in os.listdir(f\"{dataset_path}/{label}\")\n",
    "    ])\n",
    "    labels.extend([\n",
    "        label for _ in range(len(os.listdir(f\"{dataset_path}/{label}\")))\n",
    "    ])\n",
    "data = pd.DataFrame({'image_path': images, 'label': labels})\n",
    "\n",
    ", valid_data = train_test_split(data, test_size=0.09, random_state=0, stratify=data.label)\n",
    "train_data = train_data.reset_index(drop=True)\n",
    "valid_data = valid_data.reset_index(drop=True)\n",
    "print(f\"{len(train_data)} training examples, {len(valid_data)} validation examples\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../small_data/resume/doc_000636.png</td>\n",
       "      <td>resume</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../small_data/scientific_publication/doc_00005...</td>\n",
       "      <td>scientific_publication</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../small_data/scientific_publication/doc_00076...</td>\n",
       "      <td>scientific_publication</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../small_data/scientific_publication/doc_00031...</td>\n",
       "      <td>scientific_publication</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../small_data/email/doc_000165.png</td>\n",
       "      <td>email</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>../small_data/resume/doc_000301.png</td>\n",
       "      <td>resume</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>../small_data/scientific_publication/doc_00028...</td>\n",
       "      <td>scientific_publication</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>../small_data/resume/doc_000629.png</td>\n",
       "      <td>resume</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>../small_data/email/doc_000483.png</td>\n",
       "      <td>email</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>../small_data/resume/doc_000402.png</td>\n",
       "      <td>resume</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            image_path                   label\n",
       "0                  ../small_data/resume/doc_000636.png                  resume\n",
       "1    ../small_data/scientific_publication/doc_00005...  scientific_publication\n",
       "2    ../small_data/scientific_publication/doc_00076...  scientific_publication\n",
       "3    ../small_data/scientific_publication/doc_00031...  scientific_publication\n",
       "4                   ../small_data/email/doc_000165.png                   email\n",
       "..                                                 ...                     ...\n",
       "145                ../small_data/resume/doc_000301.png                  resume\n",
       "146  ../small_data/scientific_publication/doc_00028...  scientific_publication\n",
       "147                ../small_data/resume/doc_000629.png                  resume\n",
       "148                 ../small_data/email/doc_000483.png                   email\n",
       "149                ../small_data/resume/doc_000402.png                  resume\n",
       "\n",
       "[150 rows x 2 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_box(box, width, height):\n",
    "     return [\n",
    "         int(1000 * (box[0] / width)),\n",
    "         int(1000 * (box[1] / height)),\n",
    "         int(1000 * (box[2] / width)),\n",
    "         int(1000 * (box[3] / height)),\n",
    "     ]\n",
    "\n",
    "def apply_ocr(example):\n",
    "        # get the image\n",
    "        image = Image.open(example['image_path'])\n",
    "\n",
    "        width, height = image.size\n",
    "        \n",
    "        # apply ocr to the image \n",
    "        ocr_df = pytesseract.image_to_data(image, output_type='data.frame')\n",
    "        float_cols = ocr_df.select_dtypes('float').columns\n",
    "        ocr_df = ocr_df.dropna().reset_index(drop=True)\n",
    "        ocr_df[float_cols] = ocr_df[float_cols].round(0).astype(int)\n",
    "        ocr_df = ocr_df.replace(r'^\\s*$', np.nan, regex=True)\n",
    "        ocr_df = ocr_df.dropna().reset_index(drop=True)\n",
    "\n",
    "        # get the words and actual (unnormalized) bounding boxes\n",
    "        #words = [word for word in ocr_df.text if str(word) != 'nan'])\n",
    "        words = list(ocr_df.text)\n",
    "        words = [str(w) for w in words]\n",
    "        coordinates = ocr_df[['left', 'top', 'width', 'height']]\n",
    "        actual_boxes = []\n",
    "        for idx, row in coordinates.iterrows():\n",
    "            x, y, w, h = tuple(row) # the row comes in (left, top, width, height) format\n",
    "            actual_box = [x, y, x+w, y+h] # we turn it into (left, top, left+width, top+height) to get the actual box \n",
    "            actual_boxes.append(actual_box)\n",
    "        \n",
    "        # normalize the bounding boxes\n",
    "        boxes = []\n",
    "        for box in actual_boxes:\n",
    "            boxes.append(normalize_box(box, width, height))\n",
    "        \n",
    "        # add as extra columns \n",
    "        assert len(words) == len(boxes)\n",
    "        example['words'] = words\n",
    "        example['bbox'] = boxes\n",
    "        return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_training_example(example, max_seq_length=512, pad_token_box=[0, 0, 0, 0]):\n",
    "    words = example['words']\n",
    "    normalized_word_boxes = example['bbox']\n",
    "\n",
    "    assert len(words) == len(normalized_word_boxes)\n",
    "\n",
    "    token_boxes = []\n",
    "    for word, box in zip(words, normalized_word_boxes):\n",
    "        word_tokens = tokenizer.tokenize(word)\n",
    "        token_boxes.extend([box] * len(word_tokens))\n",
    "\n",
    "    # Truncation of token_boxes\n",
    "    special_tokens_count = 2 \n",
    "    if len(token_boxes) > max_seq_length - special_tokens_count:\n",
    "        token_boxes = token_boxes[: (max_seq_length - special_tokens_count)]\n",
    "\n",
    "    # add bounding boxes of cls + sep tokens\n",
    "    token_boxes = [[0, 0, 0, 0]] + token_boxes + [[1000, 1000, 1000, 1000]]\n",
    "\n",
    "    encoding = tokenizer(' '.join(words), padding='max_length', truncation=True)\n",
    "    # Padding of token_boxes up the bounding boxes to the sequence length.\n",
    "    input_ids = tokenizer(' '.join(words), truncation=True)[\"input_ids\"]\n",
    "    padding_length = max_seq_length - len(input_ids)\n",
    "    token_boxes += [pad_token_box] * padding_length\n",
    "    encoding['bbox'] = token_boxes\n",
    "    encoding['label'] = label2idx[example['label']]\n",
    "    \n",
    "\n",
    "    assert len(encoding['input_ids']) == max_seq_length\n",
    "    assert len(encoding['attention_mask']) == max_seq_length\n",
    "    assert len(encoding['token_type_ids']) == max_seq_length\n",
    "    assert len(encoding['bbox']) == max_seq_length\n",
    "\n",
    "    return encoding\n",
    "\n",
    "# we need to define the features ourselves as the bbox of LayoutLM are an extra feature\n",
    "training_features = Features({\n",
    "    'input_ids': Sequence(feature=Value(dtype='int64')),\n",
    "    'bbox': Array2D(dtype=\"int64\", shape=(512, 4)),\n",
    "    'attention_mask': Sequence(Value(dtype='int64')),\n",
    "    'token_type_ids': Sequence(Value(dtype='int64')),\n",
    "    'label': ClassLabel(names=list(idx2label.keys())),\n",
    "    'image_path': Value(dtype='string'),\n",
    "    'words': Sequence(feature=Value(dtype='string')),\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_dataloader_from_df(data):\n",
    "    dataset = Dataset.from_pandas(data)\n",
    "    dataset = dataset.map(apply_ocr)\n",
    "    encoded_dataset = dataset.map(\n",
    "        lambda example: encode_training_example(example), features=training_features\n",
    "    )\n",
    "\n",
    "    encoded_dataset.set_format(\n",
    "        type='torch', columns=['input_ids', 'bbox', 'attention_mask', 'token_type_ids', 'label']\n",
    "    )\n",
    "    dataloader = torch.utils.data.DataLoader(encoded_dataset, batch_size=1, shuffle=True)\n",
    "    batch = next(iter(dataloader))\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = LayoutLMTokenizer.from_pretrained(\"microsoft/layoutlm-base-uncased\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../small_data/email/doc_000079.png</td>\n",
       "      <td>email</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../small_data/email/doc_000111.png</td>\n",
       "      <td>email</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           image_path  label\n",
       "3  ../small_data/email/doc_000079.png  email\n",
       "4  ../small_data/email/doc_000111.png  email"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data=data.iloc[3:5]\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['image_path', 'label', 'words', 'bbox'],\n",
      "    num_rows: 2\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['input_ids', 'bbox', 'attention_mask', 'token_type_ids', 'label', 'image_path', 'words'],\n",
      "    num_rows: 2\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "test_dataloader=training_dataloader_from_df(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_dataloader = training_dataloader_from_df(train_data)\n",
    "valid_dataloader = training_dataloader_from_df(valid_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading pytorch_model.bin: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 453M/453M [13:29<00:00, 560kB/s] \n",
      "Some weights of the model checkpoint at microsoft/layoutlm-base-uncased were not used when initializing LayoutLMForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing LayoutLMForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing LayoutLMForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of LayoutLMForSequenceClassification were not initialized from the model checkpoint at microsoft/layoutlm-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = LayoutLMForSequenceClassification.from_pretrained(\n",
    "    \"microsoft/layoutlm-base-uncased\", num_labels=len(label2idx)\n",
    ")\n",
    "model.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ACER\\OneDrive\\Desktop\\PERGA\\layoutlm\\.venv\\lib\\site-packages\\transformers\\optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 150/150 [27:04<00:00, 10.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 59.9476117733866\n",
      "Training accuracy: 86.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [01:01<00:00,  4.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 5.142887474037707\n",
      "Validation accuracy: 93.33333587646484\n",
      "Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 150/150 [25:11<00:00, 10.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 3.502170089399442\n",
      "Training accuracy: 99.33333587646484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:57<00:00,  3.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 2.461893512168899\n",
      "Validation accuracy: 93.33333587646484\n",
      "Epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 150/150 [24:35<00:00,  9.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.9592245609965175\n",
      "Training accuracy: 100.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:58<00:00,  3.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 2.3664261086378247\n",
      "Validation accuracy: 93.33333587646484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "optimizer = AdamW(model.parameters(), lr=4e-5)\n",
    "num_epochs = 3\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(\"Epoch:\", epoch)\n",
    "    training_loss = 0.0\n",
    "    training_correct = 0\n",
    "    #put the model in training mode\n",
    "    model.train()\n",
    "    for batch in tqdm(train_dataloader):\n",
    "        labels = batch[\"label\"].to(device)\n",
    "        outputs = model(\n",
    "            input_ids=batch[\"input_ids\"].to(device), bbox=batch[\"bbox\"].to(device), \n",
    "            attention_mask=batch[\"attention_mask\"].to(device), \n",
    "            token_type_ids=batch[\"token_type_ids\"].to(device), \n",
    "            labels=labels\n",
    "        )\n",
    "        loss = outputs.loss\n",
    "\n",
    "        training_loss += loss.item()\n",
    "        predictions = outputs.logits.argmax(-1)\n",
    "        training_correct += (predictions == labels).float().sum()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    print(\"Training Loss:\", training_loss / batch[\"input_ids\"].shape[0])\n",
    "    training_accuracy = 100 * training_correct / len(train_data)\n",
    "    print(\"Training accuracy:\", training_accuracy.item())  \n",
    "        \n",
    "    validation_loss = 0.0\n",
    "    validation_correct = 0\n",
    "    for batch in tqdm(valid_dataloader):\n",
    "        labels = batch[\"label\"].to(device)\n",
    "        outputs = model(\n",
    "            input_ids=batch[\"input_ids\"].to(device), bbox=batch[\"bbox\"].to(device), \n",
    "            attention_mask=batch[\"attention_mask\"].to(device), \n",
    "            token_type_ids=batch[\"token_type_ids\"].to(device), \n",
    "            labels=labels\n",
    "        )\n",
    "        loss = outputs.loss\n",
    "\n",
    "        validation_loss += loss.item()\n",
    "        predictions = outputs.logits.argmax(-1)\n",
    "        validation_correct += (predictions == labels).float().sum()\n",
    "\n",
    "    print(\"Validation Loss:\", validation_loss / batch[\"input_ids\"].shape[0])\n",
    "    validation_accuracy = 100 * validation_correct / len(valid_data)\n",
    "    print(\"Validation accuracy:\", validation_accuracy.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained('saved_model/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LayoutLMForSequenceClassification(\n",
       "  (layoutlm): LayoutLMModel(\n",
       "    (embeddings): LayoutLMEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (x_position_embeddings): Embedding(1024, 768)\n",
       "      (y_position_embeddings): Embedding(1024, 768)\n",
       "      (h_position_embeddings): Embedding(1024, 768)\n",
       "      (w_position_embeddings): Embedding(1024, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): LayoutLMEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x LayoutLMLayer(\n",
       "          (attention): LayoutLMAttention(\n",
       "            (self): LayoutLMSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): LayoutLMSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): LayoutLMIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): LayoutLMOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): LayoutLMPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = LayoutLMForSequenceClassification.from_pretrained(\"saved_model\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_testing_example(example, max_seq_length=512, pad_token_box=[0, 0, 0, 0]):\n",
    "    words = example['words']\n",
    "    normalized_word_boxes = example['bbox']\n",
    "\n",
    "    assert len(words) == len(normalized_word_boxes)\n",
    "\n",
    "    token_boxes = []\n",
    "    for word, box in zip(words, normalized_word_boxes):\n",
    "        word_tokens = tokenizer.tokenize(word)\n",
    "        token_boxes.extend([box] * len(word_tokens))\n",
    "  \n",
    "    # Truncation of token_boxes\n",
    "    special_tokens_count = 2 \n",
    "    if len(token_boxes) > max_seq_length - special_tokens_count:\n",
    "        token_boxes = token_boxes[: (max_seq_length - special_tokens_count)]\n",
    "  \n",
    "    # add bounding boxes of cls + sep tokens\n",
    "    token_boxes = [[0, 0, 0, 0]] + token_boxes + [[1000, 1000, 1000, 1000]]\n",
    "\n",
    "    encoding = tokenizer(' '.join(words), padding='max_length', truncation=True)\n",
    "    # Padding of token_boxes up the bounding boxes to the sequence length.\n",
    "    input_ids = tokenizer(' '.join(words), truncation=True)[\"input_ids\"]\n",
    "    padding_length = max_seq_length - len(input_ids)\n",
    "    token_boxes += [pad_token_box] * padding_length\n",
    "    encoding['bbox'] = token_boxes\n",
    "\n",
    "    assert len(encoding['input_ids']) == max_seq_length\n",
    "    assert len(encoding['attention_mask']) == max_seq_length\n",
    "    assert len(encoding['token_type_ids']) == max_seq_length\n",
    "    assert len(encoding['bbox']) == max_seq_length\n",
    "\n",
    "    return encoding\n",
    "\n",
    "testing_features = Features({\n",
    "    'input_ids': Sequence(feature=Value(dtype='int64')),\n",
    "    'bbox': Array2D(dtype=\"int64\", shape=(512, 4)),\n",
    "    'attention_mask': Sequence(Value(dtype='int64')),\n",
    "    'token_type_ids': Sequence(Value(dtype='int64')),\n",
    "    'image_path': Value(dtype='string'),\n",
    "    'words': Sequence(feature=Value(dtype='string')),\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'email': 0.0011156846303492785, 'resume': 0.9973574280738831, 'scientific_publication': 0.001526881824247539}\n",
      "document prediction :  resume\n"
     ]
    }
   ],
   "source": [
    "query_df = pd.DataFrame(\n",
    "    {'image_path': ['../small_data/resume/doc_000294.png']}\n",
    ")\n",
    "query = Dataset.from_pandas(query_df)\n",
    "query = query.map(apply_ocr)\n",
    "query = query.map(lambda example: encode_testing_example(example), features=testing_features)\n",
    "query.set_format(\n",
    "    type='torch', columns=['input_ids', 'bbox', 'attention_mask', 'token_type_ids']\n",
    ")\n",
    "query = torch.utils.data.DataLoader(query, batch_size=1, shuffle=True)\n",
    "batch = next(iter(query))\n",
    "\n",
    "outputs = model(\n",
    "    input_ids=batch[\"input_ids\"].to(device), bbox=batch[\"bbox\"].to(device), \n",
    "    attention_mask=batch[\"attention_mask\"].to(device), \n",
    "    token_type_ids=batch[\"token_type_ids\"].to(device)\n",
    ")\n",
    "preds = torch.softmax(outputs.logits, dim=1).tolist()[0]\n",
    "pred_labels = {label:pred for label, pred in zip(label2idx.keys(), preds)}\n",
    "print(pred_labels)\n",
    "category_prediction = max(pred_labels, key=pred_labels.get)\n",
    "print(\"document prediction : \",category_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'resume'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_prediction = max(pred_labels, key=pred_labels.get)\n",
    "category_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
